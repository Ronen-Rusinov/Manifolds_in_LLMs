"""
Train sparse autoencoders on embeddings produced by dimensionality reduction scripts.

This script loads pre-computed embeddings from PCA, Isomap, or Autoencoder outputs
(generated by pca_for_each_centroid.py, isomap_for_each_centroid.py, or 
isometric_autoencoder_for_each_centroid.py) and trains sparse autoencoders on them.

Features:
- Support for multiple embedding sources (PCA, Isomap, Autoencoder)
- Configurable embedding dimensionality
- Batch processing with --offset and --count parameters
- Multiple sparsity regularization methods (L1, KL, Hoyer)
- Comprehensive evaluation and visualization

Usage:
    python train_sparse_autoencoder_on_embeddings.py \\
        --source pca \\
        --n-components 50 \\
        --latent-dim 20 \\
        --sparsity-type kl \\
        --sparsity-weight 2.0 \\
        --epochs 10000 \\
        --patience 100 \\
        --offset 0 \\
        --count 50
"""

import os
import sys
import argparse
import numpy as np
import torch
import matplotlib.pyplot as plt
from pathlib import Path
from datetime import datetime
from typing import Tuple, List, Optional

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from config_manager import load_config, add_config_argument
from SparseAutoencoder import SparseAutoencoder, TiedWeightSparseAutoencoder
from train_sparse_autoencoder import (
    train_sparse_autoencoder_with_early_stopping,
    evaluate_sparse_autoencoder,
    plot_sparse_training_history,
    plot_sparse_autoencoder_analysis,
)


def get_embeddings_path(centroid_index: int, source: str, n_components: int) -> Path:
    """Get path to embeddings for a given centroid.
    
    Args:
        centroid_index: Index of centroid (0-based)
        source: Type of embeddings ('pca', 'isomap', or 'autoencoder')
        n_components: Dimensionality of embeddings
    
    Returns:
        Path to embeddings file
    
    Raises:
        ValueError: If source is not recognized
    """
    if source not in ['pca', 'isomap', 'autoencoder']:
        raise ValueError(f"source must be 'pca', 'isomap', or 'autoencoder', got {source}")
    
    source_map = {
        'pca': f'pca_atlas_{n_components}D',
        'isomap': f'iso_atlas_{n_components}D',
        'autoencoder': f'autoencoder_atlas_{n_components}D'
    }
    
    base_dir = Path(__file__).parent.parent / 'results' / source_map[source]
    embeddings_path = (
        base_dir / f"{n_components}D" / 
        f"centroid_{centroid_index:04d}_embeddings_{n_components}D.npy"
    )
    
    return embeddings_path


def load_embeddings(centroid_index: int, source: str, n_components: int) -> Optional[np.ndarray]:
    """Load embeddings for a single centroid.
    
    Args:
        centroid_index: Index of centroid
        source: Type of embeddings
        n_components: Dimensionality
    
    Returns:
        Embeddings array or None if file doesn't exist
    """
    path = get_embeddings_path(centroid_index, source, n_components)
    
    if not path.exists():
        return None
    
    embeddings = np.load(path)
    return embeddings


def load_all_embeddings_for_range(
    offset: int,
    count: int,
    source: str,
    n_components: int,
    verbose: bool = True
) -> Tuple[np.ndarray, List[Tuple[int, int]]]:
    """Load embeddings from multiple centroids.
    
    Args:
        offset: Starting centroid index
        count: Number of centroids to load
        source: Type of embeddings
        n_components: Dimensionality
        verbose: Print loading progress
    
    Returns:
        Tuple of:
        - Combined embeddings array (total_samples, n_components)
        - List of (centroid_index, start_idx) tuples for mapping back to centroids
    
    Raises:
        ValueError: If no embeddings are found
    """
    all_embeddings = []
    centroid_mapping = []  # List of (centroid_idx, start_idx_in_combined_array)
    current_idx = 0
    
    for i, centroid_idx in enumerate(range(offset, offset + count)):
        if verbose and (i + 1) % 10 == 0 or i == 0:
            print(
                f"[{datetime.now()}] Loading embeddings for centroid {i + 1}/{count} "
                f"(centroid_idx={centroid_idx})...",
                flush=True
            )
        
        embeddings = load_embeddings(centroid_idx, source, n_components)
        
        if embeddings is None:
            print(
                f"[{datetime.now()}] Warning: No embeddings found for centroid {centroid_idx}",
                flush=True
            )
            continue
        
        all_embeddings.append(embeddings)
        centroid_mapping.append((centroid_idx, current_idx))
        current_idx += embeddings.shape[0]
    
    if not all_embeddings:
        raise ValueError(
            f"No embeddings found for centroids [{offset}, {offset + count - 1}] "
            f"with source={source}, n_components={n_components}"
        )
    
    combined = np.vstack(all_embeddings)
    
    print(
        f"[{datetime.now()}] Loaded embeddings from {len(all_embeddings)} centroids. "
        f"Combined shape: {combined.shape}",
        flush=True
    )
    
    return combined, centroid_mapping


def split_data(
    embeddings: np.ndarray,
    train_fraction: float = 0.7,
    val_fraction: float = 0.15,
    random_seed: int = 42
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """Split embeddings into train/val/test sets.
    
    Args:
        embeddings: Input embeddings array
        train_fraction: Fraction for training (default: 0.7)
        val_fraction: Fraction for validation (default: 0.15)
        random_seed: Random seed for reproducibility
    
    Returns:
        Tuple of (train_data, val_data, test_data)
    """
    np.random.seed(random_seed)
    
    n_samples = embeddings.shape[0]
    n_train = int(n_samples * train_fraction)
    n_val = int(n_samples * val_fraction)
    
    # Shuffle indices
    indices = np.random.permutation(n_samples)
    train_indices = indices[:n_train]
    val_indices = indices[n_train:n_train + n_val]
    test_indices = indices[n_train + n_val:]
    
    train_data = embeddings[train_indices]
    val_data = embeddings[val_indices]
    test_data = embeddings[test_indices]
    
    print(
        f"[{datetime.now()}] Data split: "
        f"Train={train_data.shape[0]}, Val={val_data.shape[0]}, Test={test_data.shape[0]}",
        flush=True
    )
    
    return train_data, val_data, test_data


def create_output_dir(source: str, n_components: int, latent_dim: int, centroid_index: int = None) -> Path:
    """Create output directory for results.
    
    Args:
        source: Type of embeddings
        n_components: Dimensionality of embeddings
        latent_dim: Latent dimension of sparse autoencoder
        centroid_index: Index of centroid (if training per-centroid models)
    
    Returns:
        Path to output directory
    """
    base_dir = (
        Path(__file__).parent.parent / 'results' /
        f'sparse_autoencoder_{source}_atlas_{n_components}D_latent_{latent_dim}D'
    )
    
    if centroid_index is not None:
        output_dir = base_dir / f"centroid_{centroid_index:04d}"
    else:
        output_dir = base_dir
    
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir


def train_and_evaluate(
    embeddings: np.ndarray,
    latent_dim: int,
    num_epochs: int,
    learning_rate: float,
    patience: int,
    sparsity_weight: float,
    target_sparsity: float,
    sparsity_type: str,
    use_tied_weights: bool = False,
    device: str = 'cpu',
    random_seed: int = 42
) -> Tuple:
    """Train sparse autoencoder and evaluate.
    
    Args:
        embeddings: Input embeddings (n_samples, n_features)
        latent_dim: Latent dimension
        num_epochs: Number of training epochs
        learning_rate: Learning rate
        patience: Early stopping patience
        sparsity_weight: Weight for sparsity loss
        target_sparsity: Target sparsity level (for KL)
        sparsity_type: Type of sparsity ('l1', 'kl', 'hoyer')
        use_tied_weights: Whether to use tied weight architecture
        device: Device to train on
        random_seed: Random seed
    
    Returns:
        Tuple of (model, history, eval_results)
    """
    torch.manual_seed(random_seed)
    np.random.seed(random_seed)
    
    # Convert to torch tensors
    embeddings_tensor = torch.from_numpy(embeddings).float()
    
    # Split data
    train_data, val_data, test_data = split_data(embeddings_tensor)
    
    # Create model
    input_dim = embeddings.shape[1]
    
    if use_tied_weights:
        model = TiedWeightSparseAutoencoder(
            input_dim=input_dim,
            latent_dim=latent_dim,
            device=device
        )
        print(f"[{datetime.now()}] Created TiedWeightSparseAutoencoder")
    else:
        model = SparseAutoencoder(
            input_dim=input_dim,
            latent_dim=latent_dim,
            device=device
        )
        print(f"[{datetime.now()}] Created SparseAutoencoder")
    
    # Display architecture info
    num_params = sum(p.numel() for p in model.parameters())
    print(f"[{datetime.now()}] Model parameters: {num_params:,}")
    print(f"[{datetime.now()}] Input dimension: {input_dim}")
    print(f"[{datetime.now()}] Latent dimension: {latent_dim}")
    
    # Train
    print(
        f"[{datetime.now()}] Training with sparsity_type={sparsity_type}, "
        f"sparsity_weight={sparsity_weight}, target_sparsity={target_sparsity}",
        flush=True
    )
    
    history = train_sparse_autoencoder_with_early_stopping(
        model=model,
        train_data=train_data,
        val_data=val_data,
        num_epochs=num_epochs,
        learning_rate=learning_rate,
        patience=patience,
        sparsity_weight=sparsity_weight,
        target_sparsity=target_sparsity,
        sparsity_type=sparsity_type,
        device=device
    )
    
    print(
        f"[{datetime.now()}] Training completed in {history['epochs_trained']} epochs",
        flush=True
    )
    print(
        f"[{datetime.now()}] Final train loss: {history['train_loss'][-1]:.6f}, "
        f"Final val loss: {history['val_loss'][-1]:.6f}",
        flush=True
    )
    
    # Evaluate
    print(f"[{datetime.now()}] Evaluating on test set...", flush=True)
    eval_results = evaluate_sparse_autoencoder(model, test_data, device=device)
    
    print(
        f"[{datetime.now()}] Test results: "
        f"MSE={eval_results['mean']:.6f}, "
        f"Sparsity={eval_results['sparsity_level']*100:.2f}%",
        flush=True
    )
    
    return model, history, eval_results


def save_results(
    model: torch.nn.Module,
    history: dict,
    eval_results: dict,
    embeddings_shape: Tuple,
    output_dir: Path,
    source: str,
    n_components: int,
    latent_dim: int,
    sparsity_type: str,
    sparsity_weight: float
):
    """Save model, history, and evaluation results.
    
    Args:
        model: Trained model
        history: Training history
        eval_results: Evaluation results
        embeddings_shape: Shape of input embeddings
        output_dir: Directory to save to
        source: Type of embeddings
        n_components: Dimensionality of embeddings
        latent_dim: Latent dimension
        sparsity_type: Type of sparsity
        sparsity_weight: Sparsity weight
    """
    # Save model
    model_path = output_dir / 'sparse_autoencoder_model.pt'
    torch.save(model.state_dict(), model_path)
    print(f"[{datetime.now()}] Model saved to {model_path}", flush=True)
    
    # Save training history
    history_path = output_dir / 'training_history.npy'
    np.save(
        history_path,
        {
            'train_loss': np.array(history['train_loss']),
            'train_recon_loss': np.array(history['train_recon_loss']),
            'train_sparsity_loss': np.array(history['train_sparsity_loss']),
            'val_loss': np.array(history['val_loss']),
            'val_recon_loss': np.array(history['val_recon_loss']),
            'val_sparsity_loss': np.array(history['val_sparsity_loss']),
        },
        allow_pickle=True
    )
    print(f"[{datetime.now()}] Training history saved to {history_path}", flush=True)
    
    # Save evaluation results
    eval_path = output_dir / 'evaluation_results.npy'
    np.save(
        eval_path,
        {
            'reconstruction_errors': eval_results['errors'],
            'mean_error': eval_results['mean'],
            'std_error': eval_results['std'],
            'sparsity_level': eval_results['sparsity_level'],
            'mean_activation_per_neuron': eval_results['mean_activation_per_neuron'],
        },
        allow_pickle=True
    )
    print(f"[{datetime.now()}] Evaluation results saved to {eval_path}", flush=True)
    
    # Save config/metadata
    config_path = output_dir / 'config.txt'
    with open(config_path, 'w') as f:
        f.write(f"Source: {source}\n")
        f.write(f"Embedding dimensionality: {n_components}\n")
        f.write(f"Autoencoder input dimension: {embeddings_shape[1]}\n")
        f.write(f"Autoencoder latent dimension: {latent_dim}\n")
        f.write(f"Sparsity type: {sparsity_type}\n")
        f.write(f"Sparsity weight: {sparsity_weight}\n")
        f.write(f"Number of embeddings: {embeddings_shape[0]}\n")
        f.write(f"Training epochs: {history['epochs_trained']}\n")
        f.write(f"Final validation loss: {history['val_loss'][-1]:.6f}\n")
        f.write(f"Test MSE: {eval_results['mean']:.6f}\n")
        f.write(f"Test sparsity: {eval_results['sparsity_level']*100:.2f}%\n")
    print(f"[{datetime.now()}] Config saved to {config_path}", flush=True)
    
    # Generate plots
    plot_sparse_training_history(
        history,
        save_path=str(output_dir / 'training_history.png')
    )
    plot_sparse_autoencoder_analysis(
        eval_results,
        model_name=f'Sparse Autoencoder ({source.upper()} {n_components}D)',
        save_path=str(output_dir / 'analysis.png')
    )


def main():
    print(f"[{datetime.now()}] Starting sparse autoencoder training on embeddings...", flush=True)
    
    # Parse arguments
    parser = argparse.ArgumentParser(
        description="Train sparse autoencoders on embeddings from dimensionality reduction scripts"
    )
    
    parser.add_argument(
        "--source",
        type=str,
        choices=['pca', 'isomap', 'autoencoder'],
        default='pca',
        help="Source of embeddings to use (default: pca)"
    )
    parser.add_argument(
        "--n-components",
        type=int,
        help="Dimensionality of embeddings to load"
    )
    parser.add_argument(
        "--latent-dim",
        type=int,
        default=None,
        help="Latent dimension for sparse autoencoder. If not specified, defaults to 2x n_components for overcomplete representation. Can override for smaller/larger latent spaces."
    )
    parser.add_argument(
        "--sparsity-type",
        type=str,
        choices=['l1', 'kl', 'hoyer'],
        default='l1',
        help="Type of sparsity regularization (default: l1)"
    )
    parser.add_argument(
        "--sparsity-weight",
        type=float,
        default=2.0,
        help="Weight for sparsity loss (default: 2.0)"
    )
    parser.add_argument(
        "--target-sparsity",
        type=float,
        default=0.05,
        help="Target sparsity for KL divergence (default: 0.05)"
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=1e-3,
        help="Learning rate (default: 1e-3)"
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=10000,
        help="Number of training epochs (default: 10000)"
    )
    parser.add_argument(
        "--patience",
        type=int,
        default=100,
        help="Early stopping patience (default: 100)"
    )
    parser.add_argument(
        "--tied-weights",
        action="store_true",
        help="Use tied weight architecture (reduces parameters)"
    )
    parser.add_argument(
        "--offset",
        type=int,
        default=0,
        help="Starting centroid index (default: 0)"
    )
    parser.add_argument(
        "--count",
        type=int,
        help="Number of centroids to process (default: all remaining)"
    )
    parser.add_argument(
        "--random-seed",
        type=int,
        help="Random seed for reproducibility"
    )
    
    add_config_argument(parser)
    args = parser.parse_args()
    
    # Load config
    config = load_config(args.config)
    
    # Override with CLI arguments
    if args.n_components is not None:
        n_components = args.n_components
    else:
        n_components = config.dimensionality.n_components
        print(
            f"[{datetime.now()}] Using default n_components from config: {n_components}",
            flush=True
        )
    
    # Compute latent dimension if not specified (default: 2x embedding dimension)
    if args.latent_dim is not None:
        latent_dim = args.latent_dim
    else:
        latent_dim = n_components * 2
        print(
            f"[{datetime.now()}] Computing latent_dim as 2x n_components: {latent_dim}",
            flush=True
        )
    
    if args.random_seed is not None:
        random_seed = args.random_seed
    else:
        random_seed = config.training.random_seed
    
    # Determine count from centroids if not specified
    if args.count is None:
        count = config.clustering.n_centroids - args.offset
    else:
        count = args.count
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[{datetime.now()}] Using device: {device}", flush=True)
    
    # Log parameters
    print(
        f"[{datetime.now()}] Parameters: "
        f"source={args.source}, n_components={n_components}, latent_dim={latent_dim}, "
        f"sparsity_type={args.sparsity_type}, sparsity_weight={args.sparsity_weight}, "
        f"offset={args.offset}, count={count}",
        flush=True
    )
    
    try:
        # Process each centroid separately
        print(
            f"[{datetime.now()}] Processing {count} centroids (offset={args.offset}, count={count})...",
            flush=True
        )
        
        success_count = 0
        failed_count = 0
        skipped_count = 0
        
        for i, centroid_idx in enumerate(range(args.offset, args.offset + count)):
            print(
                f"\n[{datetime.now()}] Processing centroid {i + 1}/{count} (centroid_idx={centroid_idx})...",
                flush=True
            )
            
            # Load embeddings for this centroid
            embeddings = load_embeddings(centroid_idx, args.source, n_components)
            
            if embeddings is None:
                print(
                    f"[{datetime.now()}] Skipping centroid {centroid_idx} - no embeddings found",
                    flush=True
                )
                skipped_count += 1
                continue
            
            print(f"[{datetime.now()}] Loaded embeddings shape: {embeddings.shape}", flush=True)
            
            # Check if we have enough samples
            if embeddings.shape[0] < 10:
                print(
                    f"[{datetime.now()}] Skipping centroid {centroid_idx} - only {embeddings.shape[0]} samples (need at least 10)",
                    flush=True
                )
                skipped_count += 1
                continue
            
            try:
                # Train and evaluate
                model, history, eval_results = train_and_evaluate(
                    embeddings=embeddings,
                    latent_dim=latent_dim,
                    num_epochs=args.epochs,
                    learning_rate=args.learning_rate,
                    patience=args.patience,
                    sparsity_weight=args.sparsity_weight,
                    target_sparsity=args.target_sparsity,
                    sparsity_type=args.sparsity_type,
                    use_tied_weights=args.tied_weights,
                    device=device,
                    random_seed=random_seed
                )
                
                # Save results for this centroid
                output_dir = create_output_dir(
                    args.source, n_components, latent_dim, centroid_idx
                )
                save_results(
                    model=model,
                    history=history,
                    eval_results=eval_results,
                    embeddings_shape=embeddings.shape,
                    output_dir=output_dir,
                    source=args.source,
                    n_components=n_components,
                    latent_dim=latent_dim,
                    sparsity_type=args.sparsity_type,
                    sparsity_weight=args.sparsity_weight
                )
                
                print(
                    f"[{datetime.now()}] Centroid {centroid_idx} completed successfully",
                    flush=True
                )
                success_count += 1
                
            except Exception as e:
                print(
                    f"[{datetime.now()}] Error training centroid {centroid_idx}: {e}",
                    flush=True
                )
                import traceback
                traceback.print_exc()
                failed_count += 1
                continue
        
        # Summary
        print(
            f"\n[{datetime.now()}] Pipeline completed!",
            flush=True
        )
        print(
            f"[{datetime.now()}] Summary: Success={success_count}, Failed={failed_count}, Skipped={skipped_count}",
            flush=True
        )
        print(
            f"[{datetime.now()}] Results saved to results/sparse_autoencoder_{args.source}_atlas_{n_components}D_latent_{latent_dim}D/centroid_*/",
            flush=True
        )
        
    except Exception as e:
        print(f"\n[{datetime.now()}] Error: {e}", flush=True)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
